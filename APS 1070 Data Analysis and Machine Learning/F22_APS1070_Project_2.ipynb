{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ucvm7IH6da3"
      },
      "source": [
        "# **Project 2**, APS1070 Fall 2022\n",
        "**Anomaly Detection Algorithm using Gaussian Mixture Model**\n",
        "\n",
        "**Deadline: Oct 27, 9 PM - 13 points**\n",
        "\n",
        "**Academic Integrity**\n",
        "\n",
        "This project is individual - it is to be completed on your own. If you have questions, please post your query in the APS1070 Piazza Q&A forums (the answer might be useful to others!).\n",
        "\n",
        "Do not share your code with others, or post your work online. Do not submit code that you have not written yourself. Students suspected of plagiarism on a project, midterm or exam will be referred to the department for formal discipline for breaches of the Student Code of Conduct."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGTYOwVXnmGv"
      },
      "source": [
        "Please fill out the following:\n",
        "\n",
        "\n",
        "*   Name: \n",
        "*   Student Number: "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to submit **(HTML + IPYNB)**\n",
        "\n",
        "1. Download your notebook: `File -> Download .ipynb`\n",
        "\n",
        "2. Click on the Files icon on the far left menu of Colab\n",
        "\n",
        "3. Select & upload your `.ipynb` file you just downloaded, and then obtain its path (right click) (you might need to hit the Refresh button before your file shows up)\n",
        "\n",
        "\n",
        "4. execute the following in a Colab cell:\n",
        "```\n",
        "%%shell\n",
        "jupyter nbconvert --to html /PATH/TO/YOUR/NOTEBOOKFILE.ipynb\n",
        "```\n",
        "\n",
        "5. An HTML version of your notebook will appear in the files, so you can download it.\n",
        "\n",
        "6. Submit **both** <font color='red'>`HTML` and `IPYNB`</font>  files on Quercus for grading.\n",
        "\n",
        "\n",
        "\n",
        "Ref: https://stackoverflow.com/a/64487858 \n",
        "\n"
      ],
      "metadata": {
        "id": "0czK3vQe_t2F"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVh8MGvte8bX"
      },
      "source": [
        "##**Part 1: Getting started [2 Marks]**\n",
        "\n",
        "We are going to work with a credit card fraud dataset. This dataset contains 28 key features, which are not \n",
        "directly interpretable but contain meaningful information about the dataset.\n",
        "\n",
        "Load the dataset in CSV file using Pandas. The dataset is called `creditcard.csv`. Print out the first few columns of the dataset.\n",
        "\n",
        "* How many rows are there? _____ **[0.1]**\n",
        "* What features in the dataset are present aside from the 28 main features?  _____ **[0.1]**\n",
        "* Which column contains the targets? **[0.1]**\n",
        "* What is the meaning of target values?_____ **[0.1]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9LfYqXUHbql"
      },
      "source": [
        "pip install wget"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sg0gndnDe8bd"
      },
      "source": [
        "import wget\n",
        "\n",
        "wget.download('https://github.com/aps1070-2019/datasets/raw/master/creditcard.tar.gz','creditcard.tar.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h5z71s8e8bm"
      },
      "source": [
        "!tar -zxvf creditcard.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bojUxOaHW5si"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "df = pd.read_csv('creditcard.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xR6EPYQZVoa"
      },
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w6cRXOee8b3"
      },
      "source": [
        "It's important to know how many examples we have for each class when we work with a new dataset.\n",
        "\n",
        "* What is the percentage of entries in the dataset for each class? _____ **[0.1]**\n",
        "* Is this data considered balanced or unbalanced? Why is this the case?_____ **[0.1]**\n",
        "* Why is balance/imbalance important? How might this class ditribution affect a KNN classifier for example, which we explored in Project 1? _____ **[0.5]**\n",
        "* What metrics should we use to evaluate a model in such cases _________ **[0.2]**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2kHRnhzZUTk"
      },
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4EPw3I-e8b7"
      },
      "source": [
        "Next, split the dataset into a training (65%), validation (20%) and testing set (15%). Set the random state to 40. **[0.2]**\n",
        "\n",
        "Make sure to separate out the column corresponding to the targets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZAbDaphe8bt"
      },
      "source": [
        "### Split the data  ###\n",
        "\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = 0, 0, 0, 0, 0, 0\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe41hNLJe8cQ"
      },
      "source": [
        "Now, let's take a look at the difference in distribution for some variables between fraudulent and non-fraudulent transactions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "YTGw4xNde8cV"
      },
      "source": [
        "import matplotlib.gridspec as gridspec\n",
        "features=[f for f in df.columns if 'V' in f]\n",
        "nplots=np.size(features)\n",
        "plt.figure(figsize=(15,4*nplots))\n",
        "gs = gridspec.GridSpec(nplots,1)\n",
        "for i, feat in enumerate(features):\n",
        "    ax = plt.subplot(gs[i])\n",
        "    sns.histplot(X_train[feat][y_train==1], stat=\"density\", kde=True, color=\"blue\", bins=50)\n",
        "    sns.histplot(X_train[feat][y_train==0], stat=\"density\", kde=True, color=\"red\", bins=50)\n",
        "    ax.legend(['fraudulent', 'non-fraudulent'],loc='best')\n",
        "    ax.set_xlabel('')\n",
        "    ax.set_title('Distribution of feature: ' + feat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCCCEVDHeC2P"
      },
      "source": [
        "Explain how these graphs could provide meaningful information about anomaly detection using a gaussian model. **[0.5]**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bUEj6iGrCYCa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eecAuMsDqQaC"
      },
      "source": [
        "## **Part 2: One Gaussian model with Single feature: [2 Marks]**\n",
        "We'll start by making a prediction using **a single feature of our dataset at a time**. \n",
        "\n",
        "Please note that we **only use `V` features** in our model.\n",
        "\n",
        "**a. Fitting regardless of class:**\n",
        "  1. Fit a single Gaussian distribution on a single feature of **the full training dataset** (both classes) using ``sklearn.mixture.GaussianMixture`` when ``n_components=1``. \n",
        "  2. Compute AUC (Area under the ROC Curve) based on ``sklearn.mixture.GaussianMixture.score_samples`` on both the full training set and validation set (including both classes).  \n",
        "  3. Repeat the above steps for each of the features and present your findings in a table. **[0.3]**\n",
        "  4. Find the best 3 features to distinguish fraudulent transactions from non-fraudulent transactions based on the AUC of the validation set. **[0.2]**\n",
        "  5. Make a prediction based on a model's scores: If the `score_samples` is lower than a threshold, we consider that transaction as a fraud. Find an optimal threshold that maximizes the F1 Score of the validation set for each of those 3 features separately. (Do not check every possible value for threshold, come up with a faster way!) Compute F1 score using `sklearn.metrics.f1_score`. **[0.5]**\n",
        "  7. Report Precision, Recall and F1 score on both training and validation set in a table using the threshold you found in previous step. \n",
        "  6. Report the complexity of your method (Big O notation) for determining the optimal threshold.**[0.3]**\n",
        "\n",
        "**b. Fitting based on class:**\n",
        " 1. Pick 3 features that had the best AUC in Part 2a. \n",
        " 2. repeat part 2a to compute AUC, F1 score, Precision and Recall when you fit a Gaussian **only on non-fraudulent transactions in the training set** in step 1 (instead of all the transactions).\n",
        " 3. Compare your results from parts 2a and 2b in a table (for both training and validation set). **[0.2]**\n",
        " 4. Are these results different or similar? Why?**[0.5]**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vbf34-zsbMa"
      },
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViJHrg4AfICo"
      },
      "source": [
        "## **Part 3: One Gaussian model with multiple features: [2 Marks]**\n",
        "This part is similar to Part 2, but here we will pick multiple features and set the number of components **visually**.\n",
        "\n",
        " 1. Pick two features (say, f1 and f2). \n",
        " 2. Scatter plot (plt.scatter) those features of the training set on a figure (f1 on the x-axis and f2 on the y-axis). **[0.25]**\n",
        " 3. On the scatter plot color the training set based on their class (non-fraudulents blue and fraudulents red). **[0.25]**\n",
        " 4. Based on your plots decide how many Gaussian components (``n_components``) you need to fit the data (focus on valid transactions). **[0.25]**\n",
        " 5. Fit your Gaussian model on the training set (all samples). \n",
        " 6. Compute AUC on both training and validation sets **[0.25]**\n",
        " 7. Pick 3 new pair of features and repeat steps 2 to 6. **[0.5]**\n",
        " 8. Pick the set with the highest AUC on the validation set (out of the four sets that you tried.)\n",
        " 9. Find a threshold to maximize your F1 Score on the validation set.**[0.25]**\n",
        " 10. Plot two seperate figures (one for the training data and one for the validation data) similar to step 3 and put a circle around outliers based on your threshold (use the code of the similar figure in tutorial) **[0.25]**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtcOHF9bnYY_"
      },
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEJUxd-6inbh"
      },
      "source": [
        "## **Part 4:  Two Gaussian model with single feature. [3 Marks]**\n",
        "Now we will use two separate distributions for fraudulent and non-fraudulent transactions.\n",
        "  1.  Fit a Gaussian distribution ($G_1$) on a feature of **non-fraudulent transactions** using ``sklearn.mixture.GaussianMixture`` when ``n_components=1``. **[0.5]**\n",
        "  2. Fit another Gaussian distribution ($G_2$) on the same feature but for **fraudulent transactions** using ``sklearn.mixture.GaussianMixture`` when ``n_components=1``. **[0.5]**\n",
        "  3. Compute the score samples ($S$) for both $G_1$ and $G_2$ on the **validation set** to get $S_1$ and $S_2$, respectively. **[0.5]**\n",
        "  4. Find an optimal $c$ (a real number) that maximizes validation set F1 Score for a model such that if $S_1 < c \\times S_2$, the transaction is classified as a fraud. For example, if $c=1$ we could say that if $S_2$ is greater than $S_1$, ($S_1$<$S_2$) then the transaction is a fraud (the transaction belongs to the $G_2$ distribution which represents fraudulent transactions). For start consider $c$ in $[0,10]$ with steps of 0.1, you can change this window in your experiments if needed. **[0.5]**\n",
        "  5. Repeat the steps above for all the features. What is the best F1 Score, Precision and Recall that you get for training and validation? Which feature and what c? Show your results in a table. **[0.5]**\n",
        "  6. Can we report AUC for this model? Why? **[0.5]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJpFiTj5jaAD"
      },
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac1nyvCPe8ce"
      },
      "source": [
        "## **Part 5: Multivariate and Mixture of Gaussians Distribution [3 Marks]**\n",
        "We now want to build an outlier detection model that performs well in terms of F1 score. To design your model, you can benefit from:\n",
        "\n",
        "*   No restrictions on the number of features - use as few or as many as you want! (multivariate). \n",
        "*   To fit your model, you can take advantage of the Gaussian mixture model where you can set the number of components [help](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html) .\n",
        "*   You can choose to fit your Gaussians on non-fraudulent transactions or to both classes. \n",
        "\n",
        "\n",
        "It is up to you how to design your model. Try at least 10 different models and report the AUC for both training and validation sets (if applicable) and the best F1 score, Precision and Recall (after tuning the threshold) for both training and validation sets for each model. What kind of model works better? How many features are best (and which ones)? How many Gaussians? How many components? Summarize your findings with tables or plots. **[3]**\n",
        "\n",
        "\n",
        "**HINT !**\n",
        "\n",
        "You might want to try a two gaussian model, multiple features, single component for valid transaction and multiple components for fraudulent ones! Why does it make sense to have multiple components for the fraudulent transactions?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN1H_N-TJZ0H"
      },
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NzRkO9sIwKS"
      },
      "source": [
        "## **Part 6: Evaluating performance on test set: [1 Mark]**\n",
        "**Which model worked better?** Pick your best model among all models and apply it to your test set. Report the F1 Score, Precision and Recall on the test set. **[1]**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yClYMXloe8cg"
      },
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}